# Starter Discussions for Q&A Category

## Discussion 1: Getting Started Checklist

**Title**: Complete Setup Checklist for New Users

**Content**:

New to KRL Tutorials? This checklist ensures you have everything configured correctly before diving into your first analysis.

### Environment Setup

Confirm your Python version meets requirements. Run `python --version` in your terminal. Python 3.9 or higher is required for full compatibility with all dependencies.

Verify Jupyter installation by running `jupyter --version`. Both JupyterLab and classic Notebook are supported. Choose whichever interface you prefer.

Test that you can launch Jupyter and navigate to the notebooks directory. The folder structure should be intact with all 33 tutorial directories visible.

### Dependency Installation

Install the full requirement set using `pip install -r config/requirements_opensource.txt`. This ensures all packages are present at the start.

For isolated environments, create a dedicated conda environment or virtualenv. This prevents conflicts with other Python projects on your system.

Run the verification script in any tutorial's first cell. If all imports succeed without errors, your environment is ready.

### Data Access Preparation

Decide whether to start with synthetic data or real API data. Synthetic data requires no setup and works offline. API data provides real-world patterns but requires free registration.

If using APIs, obtain keys from Census, FRED, and other sources. Store them securely in the `config/apikeys` file following the template format.

Test API connectivity with a simple data fetch before running full tutorials. This confirms authentication is working correctly.

### First Tutorial Selection

Choose a tutorial aligned with your interests and experience level. D01 (Income & Wealth) offers the gentlest introduction. Other domains work equally well if you have domain knowledge.

Review the tutorial structure: license, overview, prerequisites, tiered analysis, and references. Understanding this pattern helps you navigate all 33 tutorials.

Run one section at a time rather than executing all cells immediately. This allows you to understand each step and identify any issues incrementally.

### Common Initial Issues

If modules are missing, install them individually with `pip install [package-name]`. Some users prefer installing packages as needed rather than bulk installation.

If plots don't render, add `%matplotlib inline` to the first code cell. Some Jupyter configurations require explicit renderer specification.

If API calls fail with authentication errors, verify your keys are correctly formatted in the apikeys file with no extra spaces or quotes.

### Verification Complete

Once you've successfully run your first tutorial section without errors, you're ready to explore the full catalog. 

What was your setup experience? Share any issues you encountered and how you resolved them. Your insights help the next newcomer.

---

## Discussion 2: Understanding Error Messages

**Title**: Common Error Messages and Solutions

**Content**:

Analytics work inevitably involves debugging errors. This discussion catalogs common error messages in KRL Tutorials and their solutions.

### Module Import Errors

**Error**: `ModuleNotFoundError: No module named 'package_name'`

**Cause**: Required package not installed in your Python environment.

**Solution**: Install the missing package using `pip install package_name`. For multiple missing packages, reinstall all requirements using the requirements file.

**Prevention**: Always install dependencies before running tutorials. Conda environments can help isolate project-specific packages.

### Data Access Errors

**Error**: `API key not found` or `Authentication failed`

**Cause**: Missing or incorrectly configured API credentials.

**Solution**: Verify your API keys are in `config/apikeys` with the correct format: `KEY_NAME=actual_key_value`. No quotes needed around values.

**Alternative**: Use the synthetic data generation sections instead. These work without any API configuration.

### Jupyter Kernel Issues

**Error**: `Kernel died` or `Kernel restarting`

**Cause**: Memory exhaustion, infinite loops, or segmentation faults from compiled libraries.

**Solution**: Restart the kernel using Kernel menu â†’ Restart. For persistent issues, restart Jupyter entirely. Consider subsampling large datasets if memory is constrained.

**Prevention**: Run cells sequentially rather than executing all at once. This prevents resource exhaustion and makes debugging easier.

### Visualization Errors

**Error**: Plots not displaying or `Backend is non-GUI backend`

**Cause**: Matplotlib backend not configured for Jupyter.

**Solution**: Add `%matplotlib inline` magic command before plotting. For interactive plots, use `%matplotlib widget` or configure plotly renderer.

**Note**: Google Colab requires different configuration: `%matplotlib inline` for static plots, specific plotly setup for interactive visualizations.

### Data Type Errors

**Error**: `TypeError: unsupported operand type` or `ValueError: could not convert string to float`

**Cause**: Operations on incorrect data types, often from CSV imports defaulting to strings.

**Solution**: Check data types with `df.dtypes`. Convert using `df['column'] = df['column'].astype(float)` or specify dtypes when reading files.

**Best Practice**: Validate data types immediately after loading data. Explicit type specification prevents downstream errors.

### Statistical Errors

**Error**: `LinAlgError: Singular matrix` or `Convergence warning`

**Cause**: Perfect multicollinearity, insufficient data, or ill-conditioned matrices.

**Solution**: Check for duplicate columns, perfect correlations, or constant variables. Remove redundant features. For convergence issues, try different optimization algorithms or scale features.

**Domain Specific**: Some models require minimum sample sizes. Ensure your dataset meets statistical requirements for the chosen technique.

### Package Version Conflicts

**Error**: `AttributeError: module has no attribute` or deprecation warnings

**Cause**: Package versions incompatible with tutorial code, often from major version updates.

**Solution**: Check package versions with `pip list | grep package_name`. Downgrade if needed: `pip install package_name==X.Y.Z`. Alternatively, update code to new API.

**Long Term**: Keep a stable environment for tutorials. Create separate environments for experimentation with latest packages.

### File Path Errors

**Error**: `FileNotFoundError: No such file or directory`

**Cause**: Working directory not set correctly or relative paths broken.

**Solution**: Ensure you launched Jupyter from the repository root. Use absolute paths or `Path` objects from pathlib for robust file handling.

**Verification**: Print your current directory with `import os; print(os.getcwd())`. It should show the repository root.

### Contributing Solutions

Have you encountered an error not listed here? Share the error message, what you were trying to do, and how you resolved it. Building this knowledge base helps everyone.

For complex errors requiring detailed debugging, open a new Q&A discussion with full error traceback and context.

---

## Discussion 3: Synthetic vs Real Data

**Title**: When to Use Synthetic Data vs Real API Data

**Content**:

Every tutorial offers both synthetic data generation and real API data access. Understanding when to use each approach optimizes your learning experience.

### Synthetic Data Advantages

**Immediate Start**: No API registration, keys, or network connectivity required. Run tutorials offline on planes, trains, or anywhere without internet access.

**Perfect Reproducibility**: Synthetic data with fixed random seeds produces identical results every time. This enables exact replication of tutorial outputs for verification.

**Educational Clarity**: Synthetic data exhibits clean patterns designed to illustrate specific analytical concepts. Noise and complications are minimized for learning.

**No Rate Limits**: Generate unlimited data instantly without API throttling or daily request caps. Experiment freely without worrying about quota exhaustion.

**Controlled Experiments**: Manipulate parameters to see how changing data characteristics affects analytical results. This builds intuition about method sensitivity.

### Real Data Advantages

**Authentic Patterns**: Real-world data contains the complexity, noise, and unexpected patterns you'll encounter in practice. This prepares you for actual analytical work.

**Current Information**: APIs provide up-to-date data reflecting recent economic and social trends. Historical tutorials remain relevant with fresh data.

**Research Validity**: Analysis of real data can be cited, published, and used for policy recommendations. Synthetic data serves learning but not research purposes.

**Professional Experience**: Working with APIs, handling authentication, and dealing with data quality issues builds practical skills employers value.

**Extended Analysis**: Real data enables going beyond tutorial scope to explore questions specific to your interests or research needs.

### Decision Framework

**Choose Synthetic Data When**:
- First time through a tutorial learning the methodology
- Testing code modifications before applying to real data
- Working offline or with unreliable internet
- Teaching in classroom settings with time constraints
- Debugging issues that might be data-related

**Choose Real Data When**:
- Applying methods to research or professional projects
- Creating portfolio pieces for job applications
- Publishing analysis or policy recommendations
- Understanding current economic or social trends
- Developing intuition about real-world data quality

**Use Both Sequentially**:
- Run tutorial with synthetic data first to learn the methodology
- Verify you understand each analytical step
- Then run again with real data to see actual patterns
- Compare results to build intuition about method robustness
- Identify where synthetic assumptions differ from reality

### Making the Transition

Start every new domain with synthetic data. Master the methodology before dealing with data access complications.

Once comfortable with analysis flow, obtain necessary API keys following the installation guide. This one-time setup enables all future real data work.

When first using real data, expect different results from synthetic examples. Real data has outliers, missing values, and irregular patterns. This is normal and valuable.

Document differences between synthetic and real data results. Understanding why patterns differ deepens analytical intuition and methodological understanding.

### Hybrid Approaches

Some analysts prefer loading real data once, caching it locally, then treating cached data like synthetic data for learning. This combines authenticity with convenience.

For very large datasets, consider sampling real data to reduce computational requirements while maintaining real-world characteristics.

When teaching others, synthetic data ensures everyone sees identical results. Provide real data sections for independent exploration afterward.

### Your Experience

How do you balance synthetic and real data in your learning? Have you discovered optimal workflows? Share your approach to help others develop effective learning strategies.

What differences have you noticed between synthetic and real data results in specific domains? These insights help calibrate expectations for other learners.

---

**These starter discussions should be posted when Discussions are enabled**
