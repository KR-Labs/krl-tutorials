{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08535991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Point\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# KRL Geospatial\n",
    "from krl_geospatial.econometrics import (\n",
    "    ParallelGWR,\n",
    "    ParallelGWRResult,\n",
    "    create_parallel_gwr,\n",
    "    GeographicallyWeightedRegression,\n",
    ")\n",
    "\n",
    "print(\"✅ Imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83bee1b8",
   "metadata": {},
   "source": [
    "## 1. Generate Synthetic Spatial Data with Non-Stationary Coefficients\n",
    "\n",
    "We create a dataset where the relationship between X and Y varies spatially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef15e628",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spatially_varying_data(n=1000, seed=42):\n",
    "    \"\"\"\n",
    "    Generate data with spatially varying coefficients.\n",
    "    \n",
    "    The true model is:\n",
    "        y_i = β0(u,v) + β1(u,v)*x1 + β2(u,v)*x2 + ε\n",
    "    \n",
    "    Where coefficients vary smoothly across space.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # Generate random coordinates in unit square\n",
    "    u = np.random.uniform(0, 100, n)\n",
    "    v = np.random.uniform(0, 100, n)\n",
    "    coords = np.column_stack([u, v])\n",
    "    \n",
    "    # Generate predictors\n",
    "    x1 = np.random.normal(0, 1, n)\n",
    "    x2 = np.random.normal(0, 1, n)\n",
    "    X = np.column_stack([x1, x2])\n",
    "    \n",
    "    # Spatially varying coefficients\n",
    "    # β0 varies with latitude (north-south gradient)\n",
    "    beta0_true = 5 + 0.1 * v\n",
    "    \n",
    "    # β1 varies with longitude (east-west gradient)\n",
    "    beta1_true = 2 + 0.05 * u\n",
    "    \n",
    "    # β2 has a quadratic spatial pattern\n",
    "    beta2_true = 1 - 0.0005 * ((u - 50)**2 + (v - 50)**2)\n",
    "    \n",
    "    # Generate response\n",
    "    epsilon = np.random.normal(0, 2, n)\n",
    "    y = beta0_true + beta1_true * x1 + beta2_true * x2 + epsilon\n",
    "    \n",
    "    # Create GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        {\n",
    "            'y': y,\n",
    "            'x1': x1,\n",
    "            'x2': x2,\n",
    "            'u': u,\n",
    "            'v': v,\n",
    "            'beta0_true': beta0_true,\n",
    "            'beta1_true': beta1_true,\n",
    "            'beta2_true': beta2_true,\n",
    "        },\n",
    "        geometry=[Point(ui, vi) for ui, vi in coords],\n",
    "        crs='EPSG:32610'\n",
    "    )\n",
    "    \n",
    "    return gdf, coords, X, y\n",
    "\n",
    "# Generate data\n",
    "gdf, coords, X, y = generate_spatially_varying_data(n=2000)\n",
    "print(f\"Generated {len(gdf)} observations with spatially varying coefficients\")\n",
    "print(f\"\\nCoordinate range: u=[{coords[:,0].min():.1f}, {coords[:,0].max():.1f}], v=[{coords[:,1].min():.1f}, {coords[:,1].max():.1f}]\")\n",
    "print(f\"\\nTrue coefficient ranges:\")\n",
    "print(f\"  β0: [{gdf['beta0_true'].min():.2f}, {gdf['beta0_true'].max():.2f}]\")\n",
    "print(f\"  β1: [{gdf['beta1_true'].min():.2f}, {gdf['beta1_true'].max():.2f}]\")\n",
    "print(f\"  β2: [{gdf['beta2_true'].min():.2f}, {gdf['beta2_true'].max():.2f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540f6dfa",
   "metadata": {},
   "source": [
    "## 2. Basic Parallel GWR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac04375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Parallel GWR model with Dask backend\n",
    "pgwr = ParallelGWR(\n",
    "    kernel='gaussian',\n",
    "    adaptive=False,\n",
    "    backend='dask',\n",
    "    n_workers=4,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Fit model\n",
    "print(\"Fitting Parallel GWR...\")\n",
    "result = pgwr.fit(\n",
    "    y=y,\n",
    "    X=X,\n",
    "    coords=coords,\n",
    "    bandwidth_method='aicc'\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Model fitted in {result.execution_time:.2f} seconds\")\n",
    "print(f\"Backend: {result.backend_used}\")\n",
    "print(f\"Workers: {result.n_workers_used}\")\n",
    "print(f\"\\nModel Statistics:\")\n",
    "print(f\"  Bandwidth: {result.bandwidth:.4f}\")\n",
    "print(f\"  R²: {result.r_squared:.4f}\")\n",
    "print(f\"  Adj R²: {result.adj_r_squared:.4f}\")\n",
    "print(f\"  AICc: {result.aicc:.2f}\")\n",
    "print(f\"  Effective DF: {result.effective_df:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545a0436",
   "metadata": {},
   "source": [
    "## 3. Compare Estimated vs True Coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6777a89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract local coefficients (intercept, β1, β2)\n",
    "beta0_est = result.local_coefficients[:, 0]\n",
    "beta1_est = result.local_coefficients[:, 1]\n",
    "beta2_est = result.local_coefficients[:, 2]\n",
    "\n",
    "# Compare with true values\n",
    "print(\"Coefficient Recovery:\")\n",
    "print(f\"  β0: Correlation = {np.corrcoef(gdf['beta0_true'], beta0_est)[0,1]:.4f}\")\n",
    "print(f\"  β1: Correlation = {np.corrcoef(gdf['beta1_true'], beta1_est)[0,1]:.4f}\")\n",
    "print(f\"  β2: Correlation = {np.corrcoef(gdf['beta2_true'], beta2_est)[0,1]:.4f}\")\n",
    "\n",
    "# Visualize\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "\n",
    "# True coefficients\n",
    "for i, (col, ax) in enumerate(zip(['beta0_true', 'beta1_true', 'beta2_true'], axes[0])):\n",
    "    sc = ax.scatter(coords[:,0], coords[:,1], c=gdf[col], cmap='RdYlBu_r', s=10)\n",
    "    ax.set_title(f'True {col.replace(\"_true\", \"\")}')\n",
    "    plt.colorbar(sc, ax=ax)\n",
    "\n",
    "# Estimated coefficients\n",
    "estimates = [beta0_est, beta1_est, beta2_est]\n",
    "names = ['β0 (Intercept)', 'β1 (x1)', 'β2 (x2)']\n",
    "for i, (est, name, ax) in enumerate(zip(estimates, names, axes[1])):\n",
    "    sc = ax.scatter(coords[:,0], coords[:,1], c=est, cmap='RdYlBu_r', s=10)\n",
    "    ax.set_title(f'Estimated {name}')\n",
    "    plt.colorbar(sc, ax=ax)\n",
    "\n",
    "plt.suptitle('Parallel GWR: True vs Estimated Spatially Varying Coefficients', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51abd0c4",
   "metadata": {},
   "source": [
    "## 4. Backend Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa19367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare different backends\n",
    "backends = ['sequential', 'dask']\n",
    "timing_results = []\n",
    "\n",
    "# Use smaller dataset for fair comparison\n",
    "gdf_small, coords_small, X_small, y_small = generate_spatially_varying_data(n=500, seed=123)\n",
    "\n",
    "for backend in backends:\n",
    "    print(f\"\\nTesting {backend} backend...\")\n",
    "    \n",
    "    model = ParallelGWR(\n",
    "        kernel='gaussian',\n",
    "        backend=backend,\n",
    "        n_workers=4,\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    start = time.time()\n",
    "    result = model.fit(\n",
    "        y=y_small,\n",
    "        X=X_small,\n",
    "        coords=coords_small,\n",
    "        bandwidth=15.0  # Fixed bandwidth for fair comparison\n",
    "    )\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    timing_results.append({\n",
    "        'Backend': backend,\n",
    "        'Time (s)': elapsed,\n",
    "        'R²': result.r_squared,\n",
    "    })\n",
    "    print(f\"  Time: {elapsed:.3f}s, R²: {result.r_squared:.4f}\")\n",
    "\n",
    "# Display results\n",
    "timing_df = pd.DataFrame(timing_results)\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Backend Performance Comparison (n=500)\")\n",
    "print(\"=\"*50)\n",
    "print(timing_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887e6979",
   "metadata": {},
   "source": [
    "## 5. Bandwidth Selection Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da162c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare bandwidth selection methods\n",
    "methods = ['aic', 'aicc', 'bic', 'cv']\n",
    "bw_results = []\n",
    "\n",
    "for method in methods:\n",
    "    print(f\"\\nTesting {method.upper()} bandwidth selection...\")\n",
    "    \n",
    "    model = ParallelGWR(\n",
    "        kernel='gaussian',\n",
    "        backend='dask',\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    result = model.fit(\n",
    "        y=y_small,\n",
    "        X=X_small,\n",
    "        coords=coords_small,\n",
    "        bandwidth_method=method\n",
    "    )\n",
    "    \n",
    "    bw_results.append({\n",
    "        'Method': method.upper(),\n",
    "        'Bandwidth': result.bandwidth,\n",
    "        'R²': result.r_squared,\n",
    "        'AICc': result.aicc,\n",
    "    })\n",
    "\n",
    "bw_df = pd.DataFrame(bw_results)\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Bandwidth Selection Comparison\")\n",
    "print(\"=\"*60)\n",
    "print(bw_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee662f3",
   "metadata": {},
   "source": [
    "## 6. Large Dataset Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973f094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate larger dataset\n",
    "print(\"Generating large dataset (n=10,000)...\")\n",
    "gdf_large, coords_large, X_large, y_large = generate_spatially_varying_data(n=10000, seed=456)\n",
    "\n",
    "# Fit with parallel backend\n",
    "pgwr_large = ParallelGWR(\n",
    "    kernel='bisquare',\n",
    "    adaptive=True,\n",
    "    backend='dask',\n",
    "    n_workers=-1,  # Auto-detect\n",
    "    chunk_size=2000,\n",
    "    memory_efficient=True,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nFitting Parallel GWR on large dataset...\")\n",
    "result_large = pgwr_large.fit(\n",
    "    y=y_large,\n",
    "    X=X_large,\n",
    "    coords=coords_large,\n",
    "    bandwidth=100,  # Adaptive: k=100 nearest neighbors\n",
    ")\n",
    "\n",
    "print(f\"\\n✅ Large dataset fitted in {result_large.execution_time:.2f} seconds\")\n",
    "print(f\"R²: {result_large.r_squared:.4f}\")\n",
    "print(f\"Observations per second: {len(y_large) / result_large.execution_time:.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395dc119",
   "metadata": {},
   "source": [
    "## 7. Spatial Heterogeneity Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaa3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test for spatial heterogeneity\n",
    "heterogeneity = pgwr.test_spatial_heterogeneity()\n",
    "\n",
    "print(\"Spatial Heterogeneity Test Results:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Spatial Heterogeneity Index: {heterogeneity['spatial_heterogeneity_index']:.4f}\")\n",
    "print(f\"R² Variation: {heterogeneity['r_squared_variation']:.4f}\")\n",
    "print(f\"\\nCoefficient Statistics:\")\n",
    "\n",
    "coef_names = ['Intercept', 'β1 (x1)', 'β2 (x2)']\n",
    "for i, name in enumerate(coef_names):\n",
    "    print(f\"  {name}:\")\n",
    "    print(f\"    Std Dev: {heterogeneity['coefficient_std'][i]:.4f}\")\n",
    "    print(f\"    Range: {heterogeneity['coefficient_range'][i]:.4f}\")\n",
    "    print(f\"    CV: {heterogeneity['coefficient_variation'][i]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed21fef",
   "metadata": {},
   "source": [
    "## 8. Visualization: Local t-Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f2b2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize local t-statistics (significance of local coefficients)\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "t_stats = result.local_t_stats\n",
    "names = ['Intercept', 'β1 (x1)', 'β2 (x2)']\n",
    "\n",
    "for i, (name, ax) in enumerate(zip(names, axes)):\n",
    "    t_vals = t_stats[:, i]\n",
    "    \n",
    "    # Color by significance\n",
    "    colors = np.where(np.abs(t_vals) > 1.96, 'significant', 'not significant')\n",
    "    \n",
    "    sc = ax.scatter(\n",
    "        coords[:,0], coords[:,1],\n",
    "        c=t_vals, cmap='RdBu_r', s=10,\n",
    "        vmin=-5, vmax=5\n",
    "    )\n",
    "    ax.set_title(f'{name} t-statistics')\n",
    "    ax.set_xlabel('u')\n",
    "    ax.set_ylabel('v')\n",
    "    plt.colorbar(sc, ax=ax)\n",
    "\n",
    "plt.suptitle('Local t-Statistics (|t| > 1.96 indicates significance at α=0.05)', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Percentage significant\n",
    "for i, name in enumerate(names):\n",
    "    pct_sig = (np.abs(t_stats[:, i]) > 1.96).mean() * 100\n",
    "    print(f\"{name}: {pct_sig:.1f}% locally significant\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938ba831",
   "metadata": {},
   "source": [
    "## 9. Prediction at New Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c699853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new prediction locations\n",
    "np.random.seed(789)\n",
    "n_new = 100\n",
    "coords_new = np.random.uniform(0, 100, (n_new, 2))\n",
    "X_new = np.random.normal(0, 1, (n_new, 2))\n",
    "\n",
    "# Predict\n",
    "y_pred = pgwr.predict(X_new, coords_new)\n",
    "\n",
    "print(f\"Generated {n_new} predictions\")\n",
    "print(f\"Prediction range: [{y_pred.min():.2f}, {y_pred.max():.2f}]\")\n",
    "\n",
    "# Visualize predictions\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "# Training data (small dots)\n",
    "plt.scatter(coords[:,0], coords[:,1], c='gray', s=5, alpha=0.3, label='Training')\n",
    "\n",
    "# Predictions (larger colored dots)\n",
    "sc = plt.scatter(coords_new[:,0], coords_new[:,1], c=y_pred, cmap='viridis', s=50, edgecolors='black', label='Predictions')\n",
    "plt.colorbar(sc, label='Predicted y')\n",
    "\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('v')\n",
    "plt.title('Parallel GWR Predictions at New Locations')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0eb077",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated **Parallel GWR** from `krl-geospatial-tools`:\n",
    "\n",
    "### Key Features Demonstrated\n",
    "1. **Dask Parallelization** - Multi-core CPU execution\n",
    "2. **Multiple Kernels** - Gaussian, bisquare, tricube, etc.\n",
    "3. **Adaptive Bandwidth** - k-NN based spatial weighting\n",
    "4. **Bandwidth Selection** - AIC, AICc, BIC, CV methods\n",
    "5. **Large Dataset Handling** - Memory-efficient chunked processing\n",
    "6. **Spatial Heterogeneity Tests** - Coefficient variation analysis\n",
    "7. **Prediction** - Inverse distance weighted coefficient interpolation\n",
    "\n",
    "### Performance Benefits\n",
    "- **Sequential → Dask**: Up to 4-8x speedup on multi-core systems\n",
    "- **GPU acceleration**: Additional 10-50x for 10k+ observations\n",
    "- **Memory efficient**: Handles 100k+ observations via chunking\n",
    "\n",
    "### References\n",
    "- Fotheringham, Brunsdon & Charlton (2002). *Geographically Weighted Regression*. Wiley.\n",
    "- Oshan et al. (2019). *A fast GWR implementation*. IJGIS."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
